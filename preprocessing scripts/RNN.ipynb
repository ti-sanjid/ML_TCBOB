{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ocGCUniqDg9L",
   "metadata": {
    "id": "ocGCUniqDg9L"
   },
   "outputs": [],
   "source": [
    "# !pip install numpy==1.20.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "KPfWRd8eCUZf",
   "metadata": {
    "id": "KPfWRd8eCUZf"
   },
   "outputs": [],
   "source": [
    "# !apt-get install -qq libgdal-dev libproj-dev\n",
    "# #!pip install --no-binary shapely shapely\n",
    "# !pip install --no-binary shapely shapely --force\n",
    "# !pip install cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7398f4e9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7398f4e9",
    "outputId": "7768ea90-e264-4fef-be58-df3bd1f01d16"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-02 22:29:28.816111: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36638f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cphpa8iQARaP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cphpa8iQARaP",
    "outputId": "c26c9a6a-bb55-4137-d703-3c3650183adf"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "052dc468",
   "metadata": {
    "id": "052dc468"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/mnt/1A42C1DD42C1BE2F/MyProjects/ML_TCBOB/Data/Preprocessed data/filtered_all_cyclone[4th august 2023].csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "F8LZX6kgFCAs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 808
    },
    "id": "F8LZX6kgFCAs",
    "outputId": "fbd5b248-06e3-4376-f753-8f8601e23b09"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cyclone_no</th>\n",
       "      <th>Date</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>eye</th>\n",
       "      <th>eye.1</th>\n",
       "      <th>eye.2</th>\n",
       "      <th>eye.3</th>\n",
       "      <th>eye.4</th>\n",
       "      <th>eye.5</th>\n",
       "      <th>...</th>\n",
       "      <th>rquv grid.2800</th>\n",
       "      <th>rquv grid.2801</th>\n",
       "      <th>rquv grid.2802</th>\n",
       "      <th>rquv grid.2803</th>\n",
       "      <th>rquv grid.2804</th>\n",
       "      <th>rquv grid.2805</th>\n",
       "      <th>rquv grid.2806</th>\n",
       "      <th>rquv grid.2807</th>\n",
       "      <th>lat+6</th>\n",
       "      <th>lon+6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1979-05-07 22:00:00</td>\n",
       "      <td>6.75</td>\n",
       "      <td>86.50</td>\n",
       "      <td>95.660950</td>\n",
       "      <td>97.736984</td>\n",
       "      <td>95.491577</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.005992</td>\n",
       "      <td>0.014564</td>\n",
       "      <td>...</td>\n",
       "      <td>302.293976</td>\n",
       "      <td>302.067444</td>\n",
       "      <td>302.128967</td>\n",
       "      <td>302.358368</td>\n",
       "      <td>302.762665</td>\n",
       "      <td>302.859283</td>\n",
       "      <td>302.898346</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.75</td>\n",
       "      <td>86.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1979-05-07 23:00:00</td>\n",
       "      <td>6.75</td>\n",
       "      <td>86.25</td>\n",
       "      <td>93.597015</td>\n",
       "      <td>97.013519</td>\n",
       "      <td>92.399307</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.005942</td>\n",
       "      <td>0.014518</td>\n",
       "      <td>...</td>\n",
       "      <td>302.293976</td>\n",
       "      <td>302.067444</td>\n",
       "      <td>302.128967</td>\n",
       "      <td>302.358368</td>\n",
       "      <td>302.762665</td>\n",
       "      <td>302.859283</td>\n",
       "      <td>302.898346</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.75</td>\n",
       "      <td>86.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1979-05-08 00:00:00</td>\n",
       "      <td>6.75</td>\n",
       "      <td>86.25</td>\n",
       "      <td>96.556213</td>\n",
       "      <td>92.251709</td>\n",
       "      <td>94.831024</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.005842</td>\n",
       "      <td>0.014695</td>\n",
       "      <td>...</td>\n",
       "      <td>302.293976</td>\n",
       "      <td>302.067444</td>\n",
       "      <td>302.128967</td>\n",
       "      <td>302.358368</td>\n",
       "      <td>302.762665</td>\n",
       "      <td>302.859283</td>\n",
       "      <td>302.898346</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.75</td>\n",
       "      <td>86.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1979-05-08 01:00:00</td>\n",
       "      <td>6.75</td>\n",
       "      <td>86.00</td>\n",
       "      <td>98.818558</td>\n",
       "      <td>98.317696</td>\n",
       "      <td>94.402756</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.005979</td>\n",
       "      <td>0.014798</td>\n",
       "      <td>...</td>\n",
       "      <td>302.293976</td>\n",
       "      <td>302.067444</td>\n",
       "      <td>302.128967</td>\n",
       "      <td>302.358368</td>\n",
       "      <td>302.762665</td>\n",
       "      <td>302.859283</td>\n",
       "      <td>302.898346</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.75</td>\n",
       "      <td>86.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1979-05-08 02:00:00</td>\n",
       "      <td>6.75</td>\n",
       "      <td>86.00</td>\n",
       "      <td>100.057404</td>\n",
       "      <td>97.221611</td>\n",
       "      <td>92.912262</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.006008</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>...</td>\n",
       "      <td>302.293976</td>\n",
       "      <td>302.067444</td>\n",
       "      <td>302.128967</td>\n",
       "      <td>302.358368</td>\n",
       "      <td>302.762665</td>\n",
       "      <td>302.859283</td>\n",
       "      <td>302.898346</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.75</td>\n",
       "      <td>86.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3781</th>\n",
       "      <td>49</td>\n",
       "      <td>2020-05-20 10:00:00</td>\n",
       "      <td>21.50</td>\n",
       "      <td>88.00</td>\n",
       "      <td>101.143356</td>\n",
       "      <td>97.755447</td>\n",
       "      <td>90.524521</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>0.017035</td>\n",
       "      <td>...</td>\n",
       "      <td>302.579834</td>\n",
       "      <td>302.588623</td>\n",
       "      <td>302.683289</td>\n",
       "      <td>302.565247</td>\n",
       "      <td>302.612030</td>\n",
       "      <td>302.591644</td>\n",
       "      <td>302.658813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.75</td>\n",
       "      <td>88.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3782</th>\n",
       "      <td>49</td>\n",
       "      <td>2020-05-20 11:00:00</td>\n",
       "      <td>21.75</td>\n",
       "      <td>88.25</td>\n",
       "      <td>100.676369</td>\n",
       "      <td>95.485931</td>\n",
       "      <td>90.572113</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.008171</td>\n",
       "      <td>0.016890</td>\n",
       "      <td>...</td>\n",
       "      <td>302.579834</td>\n",
       "      <td>302.588623</td>\n",
       "      <td>302.683289</td>\n",
       "      <td>302.565247</td>\n",
       "      <td>302.612030</td>\n",
       "      <td>302.591644</td>\n",
       "      <td>302.658813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.00</td>\n",
       "      <td>88.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3783</th>\n",
       "      <td>49</td>\n",
       "      <td>2020-05-20 12:00:00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>88.25</td>\n",
       "      <td>100.126091</td>\n",
       "      <td>91.098595</td>\n",
       "      <td>93.382980</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.007944</td>\n",
       "      <td>0.017346</td>\n",
       "      <td>...</td>\n",
       "      <td>302.579834</td>\n",
       "      <td>302.588623</td>\n",
       "      <td>302.683289</td>\n",
       "      <td>302.565247</td>\n",
       "      <td>302.612030</td>\n",
       "      <td>302.591644</td>\n",
       "      <td>302.658813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.25</td>\n",
       "      <td>88.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3784</th>\n",
       "      <td>49</td>\n",
       "      <td>2020-05-20 13:00:00</td>\n",
       "      <td>22.25</td>\n",
       "      <td>88.25</td>\n",
       "      <td>101.419983</td>\n",
       "      <td>89.391251</td>\n",
       "      <td>94.638206</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.007829</td>\n",
       "      <td>0.016972</td>\n",
       "      <td>...</td>\n",
       "      <td>302.579834</td>\n",
       "      <td>302.588623</td>\n",
       "      <td>302.683289</td>\n",
       "      <td>302.565247</td>\n",
       "      <td>302.612030</td>\n",
       "      <td>302.591644</td>\n",
       "      <td>302.658813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.25</td>\n",
       "      <td>88.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3785</th>\n",
       "      <td>49</td>\n",
       "      <td>2020-05-20 14:00:00</td>\n",
       "      <td>22.50</td>\n",
       "      <td>88.25</td>\n",
       "      <td>104.923904</td>\n",
       "      <td>89.879066</td>\n",
       "      <td>95.363976</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.007713</td>\n",
       "      <td>0.016826</td>\n",
       "      <td>...</td>\n",
       "      <td>302.579834</td>\n",
       "      <td>302.588623</td>\n",
       "      <td>302.683289</td>\n",
       "      <td>302.565247</td>\n",
       "      <td>302.612030</td>\n",
       "      <td>302.591644</td>\n",
       "      <td>302.658813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.50</td>\n",
       "      <td>88.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3786 rows × 2826 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cyclone_no                 Date    lat    lon         eye      eye.1  \\\n",
       "0              1  1979-05-07 22:00:00   6.75  86.50   95.660950  97.736984   \n",
       "1              1  1979-05-07 23:00:00   6.75  86.25   93.597015  97.013519   \n",
       "2              1  1979-05-08 00:00:00   6.75  86.25   96.556213  92.251709   \n",
       "3              1  1979-05-08 01:00:00   6.75  86.00   98.818558  98.317696   \n",
       "4              1  1979-05-08 02:00:00   6.75  86.00  100.057404  97.221611   \n",
       "...          ...                  ...    ...    ...         ...        ...   \n",
       "3781          49  2020-05-20 10:00:00  21.50  88.00  101.143356  97.755447   \n",
       "3782          49  2020-05-20 11:00:00  21.75  88.25  100.676369  95.485931   \n",
       "3783          49  2020-05-20 12:00:00  22.00  88.25  100.126091  91.098595   \n",
       "3784          49  2020-05-20 13:00:00  22.25  88.25  101.419983  89.391251   \n",
       "3785          49  2020-05-20 14:00:00  22.50  88.25  104.923904  89.879066   \n",
       "\n",
       "          eye.2     eye.3     eye.4     eye.5  ...  rquv grid.2800  \\\n",
       "0     95.491577  0.000016  0.005992  0.014564  ...      302.293976   \n",
       "1     92.399307  0.000016  0.005942  0.014518  ...      302.293976   \n",
       "2     94.831024  0.000015  0.005842  0.014695  ...      302.293976   \n",
       "3     94.402756  0.000016  0.005979  0.014798  ...      302.293976   \n",
       "4     92.912262  0.000016  0.006008  0.014700  ...      302.293976   \n",
       "...         ...       ...       ...       ...  ...             ...   \n",
       "3781  90.524521  0.000051  0.008797  0.017035  ...      302.579834   \n",
       "3782  90.572113  0.000050  0.008171  0.016890  ...      302.579834   \n",
       "3783  93.382980  0.000049  0.007944  0.017346  ...      302.579834   \n",
       "3784  94.638206  0.000048  0.007829  0.016972  ...      302.579834   \n",
       "3785  95.363976  0.000048  0.007713  0.016826  ...      302.579834   \n",
       "\n",
       "      rquv grid.2801  rquv grid.2802  rquv grid.2803  rquv grid.2804  \\\n",
       "0         302.067444      302.128967      302.358368      302.762665   \n",
       "1         302.067444      302.128967      302.358368      302.762665   \n",
       "2         302.067444      302.128967      302.358368      302.762665   \n",
       "3         302.067444      302.128967      302.358368      302.762665   \n",
       "4         302.067444      302.128967      302.358368      302.762665   \n",
       "...              ...             ...             ...             ...   \n",
       "3781      302.588623      302.683289      302.565247      302.612030   \n",
       "3782      302.588623      302.683289      302.565247      302.612030   \n",
       "3783      302.588623      302.683289      302.565247      302.612030   \n",
       "3784      302.588623      302.683289      302.565247      302.612030   \n",
       "3785      302.588623      302.683289      302.565247      302.612030   \n",
       "\n",
       "      rquv grid.2805  rquv grid.2806  rquv grid.2807  lat+6  lon+6  \n",
       "0         302.859283      302.898346             NaN   6.75  86.00  \n",
       "1         302.859283      302.898346             NaN   6.75  86.00  \n",
       "2         302.859283      302.898346             NaN   6.75  86.00  \n",
       "3         302.859283      302.898346             NaN   6.75  86.00  \n",
       "4         302.859283      302.898346             NaN   6.75  86.00  \n",
       "...              ...             ...             ...    ...    ...  \n",
       "3781      302.591644      302.658813             NaN  22.75  88.25  \n",
       "3782      302.591644      302.658813             NaN  23.00  88.50  \n",
       "3783      302.591644      302.658813             NaN  23.25  88.50  \n",
       "3784      302.591644      302.658813             NaN  23.25  88.50  \n",
       "3785      302.591644      302.658813             NaN  23.50  88.50  \n",
       "\n",
       "[3786 rows x 2826 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e20a92b",
   "metadata": {
    "id": "6e20a92b"
   },
   "outputs": [],
   "source": [
    "# df2 = df.fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "KC952PkVjRlb",
   "metadata": {
    "id": "KC952PkVjRlb"
   },
   "outputs": [],
   "source": [
    "# df2.insert(loc = 0,\n",
    "#           column = 'index',\n",
    "#           value = df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fad61da7",
   "metadata": {
    "id": "fad61da7"
   },
   "outputs": [],
   "source": [
    "# year = pd.to_datetime(df2['ISO_TIME'], format='%Y-%m-%d').dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9babf1f4",
   "metadata": {
    "id": "9babf1f4"
   },
   "outputs": [],
   "source": [
    "# month = pd.to_datetime(df2['ISO_TIME'], format='%Y-%m-%d').dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3579b874",
   "metadata": {
    "id": "3579b874"
   },
   "outputs": [],
   "source": [
    "# day = pd.to_datetime(df2['ISO_TIME'], format='%Y-%m-%d').dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d8e415e",
   "metadata": {
    "id": "5d8e415e"
   },
   "outputs": [],
   "source": [
    "# ee = pd.to_datetime(df2['ISO_TIME'], format='%Y-%m-%d').dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a1f5eeb",
   "metadata": {
    "id": "8a1f5eeb"
   },
   "outputs": [],
   "source": [
    "# hour = pd.to_datetime(ee, format='%H:%M:%S').dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "beb4b1a1",
   "metadata": {
    "id": "beb4b1a1"
   },
   "outputs": [],
   "source": [
    "# df2['ISO_TIME'] = hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "tf4k7VjtzwkR",
   "metadata": {
    "id": "tf4k7VjtzwkR"
   },
   "outputs": [],
   "source": [
    "# for i in df2.ISO_TIME:\n",
    "#   if i ==0:\n",
    "#    df2['Lat +6'] = df2['lat']\n",
    "#    df2['Lon +6'] = df2['lon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "hIjVPPbYAXFy",
   "metadata": {
    "id": "hIjVPPbYAXFy"
   },
   "outputs": [],
   "source": [
    "df2=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ePaoyLqBAMmi",
   "metadata": {
    "id": "ePaoyLqBAMmi"
   },
   "outputs": [],
   "source": [
    "# df2['Lat +6'].fillna(method='ffill', inplace=True)\n",
    "# df2['Lon +6'].fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "Pz3qWTTK0Wrm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 808
    },
    "id": "Pz3qWTTK0Wrm",
    "outputId": "22f459ee-1d1b-4ccb-c1eb-a38f90dee0cd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>eye</th>\n",
       "      <th>eye.1</th>\n",
       "      <th>eye.2</th>\n",
       "      <th>eye.3</th>\n",
       "      <th>eye.4</th>\n",
       "      <th>eye.5</th>\n",
       "      <th>...</th>\n",
       "      <th>rquv grid.2800</th>\n",
       "      <th>rquv grid.2801</th>\n",
       "      <th>rquv grid.2802</th>\n",
       "      <th>rquv grid.2803</th>\n",
       "      <th>rquv grid.2804</th>\n",
       "      <th>rquv grid.2805</th>\n",
       "      <th>rquv grid.2806</th>\n",
       "      <th>rquv grid.2807</th>\n",
       "      <th>lat+6</th>\n",
       "      <th>lon+6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1979-05-07 22:00:00</td>\n",
       "      <td>6.75</td>\n",
       "      <td>86.50</td>\n",
       "      <td>95.660950</td>\n",
       "      <td>97.736984</td>\n",
       "      <td>95.491577</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.005992</td>\n",
       "      <td>0.014564</td>\n",
       "      <td>...</td>\n",
       "      <td>302.293976</td>\n",
       "      <td>302.067444</td>\n",
       "      <td>302.128967</td>\n",
       "      <td>302.358368</td>\n",
       "      <td>302.762665</td>\n",
       "      <td>302.859283</td>\n",
       "      <td>302.898346</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.75</td>\n",
       "      <td>86.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1979-05-07 23:00:00</td>\n",
       "      <td>6.75</td>\n",
       "      <td>86.25</td>\n",
       "      <td>93.597015</td>\n",
       "      <td>97.013519</td>\n",
       "      <td>92.399307</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.005942</td>\n",
       "      <td>0.014518</td>\n",
       "      <td>...</td>\n",
       "      <td>302.293976</td>\n",
       "      <td>302.067444</td>\n",
       "      <td>302.128967</td>\n",
       "      <td>302.358368</td>\n",
       "      <td>302.762665</td>\n",
       "      <td>302.859283</td>\n",
       "      <td>302.898346</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.75</td>\n",
       "      <td>86.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1979-05-08 00:00:00</td>\n",
       "      <td>6.75</td>\n",
       "      <td>86.25</td>\n",
       "      <td>96.556213</td>\n",
       "      <td>92.251709</td>\n",
       "      <td>94.831024</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.005842</td>\n",
       "      <td>0.014695</td>\n",
       "      <td>...</td>\n",
       "      <td>302.293976</td>\n",
       "      <td>302.067444</td>\n",
       "      <td>302.128967</td>\n",
       "      <td>302.358368</td>\n",
       "      <td>302.762665</td>\n",
       "      <td>302.859283</td>\n",
       "      <td>302.898346</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.75</td>\n",
       "      <td>86.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1979-05-08 01:00:00</td>\n",
       "      <td>6.75</td>\n",
       "      <td>86.00</td>\n",
       "      <td>98.818558</td>\n",
       "      <td>98.317696</td>\n",
       "      <td>94.402756</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.005979</td>\n",
       "      <td>0.014798</td>\n",
       "      <td>...</td>\n",
       "      <td>302.293976</td>\n",
       "      <td>302.067444</td>\n",
       "      <td>302.128967</td>\n",
       "      <td>302.358368</td>\n",
       "      <td>302.762665</td>\n",
       "      <td>302.859283</td>\n",
       "      <td>302.898346</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.75</td>\n",
       "      <td>86.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1979-05-08 02:00:00</td>\n",
       "      <td>6.75</td>\n",
       "      <td>86.00</td>\n",
       "      <td>100.057404</td>\n",
       "      <td>97.221611</td>\n",
       "      <td>92.912262</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.006008</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>...</td>\n",
       "      <td>302.293976</td>\n",
       "      <td>302.067444</td>\n",
       "      <td>302.128967</td>\n",
       "      <td>302.358368</td>\n",
       "      <td>302.762665</td>\n",
       "      <td>302.859283</td>\n",
       "      <td>302.898346</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.75</td>\n",
       "      <td>86.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3781</th>\n",
       "      <td>49</td>\n",
       "      <td>2020-05-20 10:00:00</td>\n",
       "      <td>21.50</td>\n",
       "      <td>88.00</td>\n",
       "      <td>101.143356</td>\n",
       "      <td>97.755447</td>\n",
       "      <td>90.524521</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>0.017035</td>\n",
       "      <td>...</td>\n",
       "      <td>302.579834</td>\n",
       "      <td>302.588623</td>\n",
       "      <td>302.683289</td>\n",
       "      <td>302.565247</td>\n",
       "      <td>302.612030</td>\n",
       "      <td>302.591644</td>\n",
       "      <td>302.658813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.75</td>\n",
       "      <td>88.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3782</th>\n",
       "      <td>49</td>\n",
       "      <td>2020-05-20 11:00:00</td>\n",
       "      <td>21.75</td>\n",
       "      <td>88.25</td>\n",
       "      <td>100.676369</td>\n",
       "      <td>95.485931</td>\n",
       "      <td>90.572113</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.008171</td>\n",
       "      <td>0.016890</td>\n",
       "      <td>...</td>\n",
       "      <td>302.579834</td>\n",
       "      <td>302.588623</td>\n",
       "      <td>302.683289</td>\n",
       "      <td>302.565247</td>\n",
       "      <td>302.612030</td>\n",
       "      <td>302.591644</td>\n",
       "      <td>302.658813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.00</td>\n",
       "      <td>88.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3783</th>\n",
       "      <td>49</td>\n",
       "      <td>2020-05-20 12:00:00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>88.25</td>\n",
       "      <td>100.126091</td>\n",
       "      <td>91.098595</td>\n",
       "      <td>93.382980</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.007944</td>\n",
       "      <td>0.017346</td>\n",
       "      <td>...</td>\n",
       "      <td>302.579834</td>\n",
       "      <td>302.588623</td>\n",
       "      <td>302.683289</td>\n",
       "      <td>302.565247</td>\n",
       "      <td>302.612030</td>\n",
       "      <td>302.591644</td>\n",
       "      <td>302.658813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.25</td>\n",
       "      <td>88.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3784</th>\n",
       "      <td>49</td>\n",
       "      <td>2020-05-20 13:00:00</td>\n",
       "      <td>22.25</td>\n",
       "      <td>88.25</td>\n",
       "      <td>101.419983</td>\n",
       "      <td>89.391251</td>\n",
       "      <td>94.638206</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.007829</td>\n",
       "      <td>0.016972</td>\n",
       "      <td>...</td>\n",
       "      <td>302.579834</td>\n",
       "      <td>302.588623</td>\n",
       "      <td>302.683289</td>\n",
       "      <td>302.565247</td>\n",
       "      <td>302.612030</td>\n",
       "      <td>302.591644</td>\n",
       "      <td>302.658813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.25</td>\n",
       "      <td>88.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3785</th>\n",
       "      <td>49</td>\n",
       "      <td>2020-05-20 14:00:00</td>\n",
       "      <td>22.50</td>\n",
       "      <td>88.25</td>\n",
       "      <td>104.923904</td>\n",
       "      <td>89.879066</td>\n",
       "      <td>95.363976</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.007713</td>\n",
       "      <td>0.016826</td>\n",
       "      <td>...</td>\n",
       "      <td>302.579834</td>\n",
       "      <td>302.588623</td>\n",
       "      <td>302.683289</td>\n",
       "      <td>302.565247</td>\n",
       "      <td>302.612030</td>\n",
       "      <td>302.591644</td>\n",
       "      <td>302.658813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.50</td>\n",
       "      <td>88.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3786 rows × 2826 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Number                 Date    lat    lon         eye      eye.1  \\\n",
       "0          1  1979-05-07 22:00:00   6.75  86.50   95.660950  97.736984   \n",
       "1          1  1979-05-07 23:00:00   6.75  86.25   93.597015  97.013519   \n",
       "2          1  1979-05-08 00:00:00   6.75  86.25   96.556213  92.251709   \n",
       "3          1  1979-05-08 01:00:00   6.75  86.00   98.818558  98.317696   \n",
       "4          1  1979-05-08 02:00:00   6.75  86.00  100.057404  97.221611   \n",
       "...      ...                  ...    ...    ...         ...        ...   \n",
       "3781      49  2020-05-20 10:00:00  21.50  88.00  101.143356  97.755447   \n",
       "3782      49  2020-05-20 11:00:00  21.75  88.25  100.676369  95.485931   \n",
       "3783      49  2020-05-20 12:00:00  22.00  88.25  100.126091  91.098595   \n",
       "3784      49  2020-05-20 13:00:00  22.25  88.25  101.419983  89.391251   \n",
       "3785      49  2020-05-20 14:00:00  22.50  88.25  104.923904  89.879066   \n",
       "\n",
       "          eye.2     eye.3     eye.4     eye.5  ...  rquv grid.2800  \\\n",
       "0     95.491577  0.000016  0.005992  0.014564  ...      302.293976   \n",
       "1     92.399307  0.000016  0.005942  0.014518  ...      302.293976   \n",
       "2     94.831024  0.000015  0.005842  0.014695  ...      302.293976   \n",
       "3     94.402756  0.000016  0.005979  0.014798  ...      302.293976   \n",
       "4     92.912262  0.000016  0.006008  0.014700  ...      302.293976   \n",
       "...         ...       ...       ...       ...  ...             ...   \n",
       "3781  90.524521  0.000051  0.008797  0.017035  ...      302.579834   \n",
       "3782  90.572113  0.000050  0.008171  0.016890  ...      302.579834   \n",
       "3783  93.382980  0.000049  0.007944  0.017346  ...      302.579834   \n",
       "3784  94.638206  0.000048  0.007829  0.016972  ...      302.579834   \n",
       "3785  95.363976  0.000048  0.007713  0.016826  ...      302.579834   \n",
       "\n",
       "      rquv grid.2801  rquv grid.2802  rquv grid.2803  rquv grid.2804  \\\n",
       "0         302.067444      302.128967      302.358368      302.762665   \n",
       "1         302.067444      302.128967      302.358368      302.762665   \n",
       "2         302.067444      302.128967      302.358368      302.762665   \n",
       "3         302.067444      302.128967      302.358368      302.762665   \n",
       "4         302.067444      302.128967      302.358368      302.762665   \n",
       "...              ...             ...             ...             ...   \n",
       "3781      302.588623      302.683289      302.565247      302.612030   \n",
       "3782      302.588623      302.683289      302.565247      302.612030   \n",
       "3783      302.588623      302.683289      302.565247      302.612030   \n",
       "3784      302.588623      302.683289      302.565247      302.612030   \n",
       "3785      302.588623      302.683289      302.565247      302.612030   \n",
       "\n",
       "      rquv grid.2805  rquv grid.2806  rquv grid.2807  lat+6  lon+6  \n",
       "0         302.859283      302.898346             NaN   6.75  86.00  \n",
       "1         302.859283      302.898346             NaN   6.75  86.00  \n",
       "2         302.859283      302.898346             NaN   6.75  86.00  \n",
       "3         302.859283      302.898346             NaN   6.75  86.00  \n",
       "4         302.859283      302.898346             NaN   6.75  86.00  \n",
       "...              ...             ...             ...    ...    ...  \n",
       "3781      302.591644      302.658813             NaN  22.75  88.25  \n",
       "3782      302.591644      302.658813             NaN  23.00  88.50  \n",
       "3783      302.591644      302.658813             NaN  23.25  88.50  \n",
       "3784      302.591644      302.658813             NaN  23.25  88.50  \n",
       "3785      302.591644      302.658813             NaN  23.50  88.50  \n",
       "\n",
       "[3786 rows x 2826 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=df2.rename(columns={'cyclone_no':'Number'})\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d23f165",
   "metadata": {
    "id": "1d23f165"
   },
   "outputs": [],
   "source": [
    "#select features and target\n",
    "X = df2.iloc[:, :-2].values #for 6 hours prediction\n",
    "Y=np.column_stack((df2['lat+6'],df2['lon+6']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78429091",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "78429091",
    "outputId": "e279a1e1-ed35-49be-e8d2-8938fa338811"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1979-05-07 22:00:00', '1979-05-07 23:00:00',\n",
       "       '1979-05-08 00:00:00', ..., '2020-05-20 12:00:00',\n",
       "       '2020-05-20 13:00:00', '2020-05-20 14:00:00'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed13bf6f",
   "metadata": {
    "id": "ed13bf6f"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_date=LabelEncoder()\n",
    "X[:,1]=le_date.fit_transform(X[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "uQmvsHVFByQ0",
   "metadata": {
    "id": "uQmvsHVFByQ0"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan,strategy='mean')\n",
    "X = imputer.fit_transform(X)\n",
    "Y = imputer.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7j6SrcCRB3t8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7j6SrcCRB3t8",
    "outputId": "bb41fe2f-c7cc-4ece-a14b-415509271470"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 0.00000000e+00, 6.75000000e+00, ...,\n",
       "        3.02762665e+02, 3.02859283e+02, 3.02898346e+02],\n",
       "       [1.00000000e+00, 1.00000000e+00, 6.75000000e+00, ...,\n",
       "        3.02762665e+02, 3.02859283e+02, 3.02898346e+02],\n",
       "       [1.00000000e+00, 2.00000000e+00, 6.75000000e+00, ...,\n",
       "        3.02762665e+02, 3.02859283e+02, 3.02898346e+02],\n",
       "       ...,\n",
       "       [4.90000000e+01, 3.78300000e+03, 2.20000000e+01, ...,\n",
       "        3.02612030e+02, 3.02591644e+02, 3.02658813e+02],\n",
       "       [4.90000000e+01, 3.78400000e+03, 2.22500000e+01, ...,\n",
       "        3.02612030e+02, 3.02591644e+02, 3.02658813e+02],\n",
       "       [4.90000000e+01, 3.78500000e+03, 2.25000000e+01, ...,\n",
       "        3.02612030e+02, 3.02591644e+02, 3.02658813e+02]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8aIX1NP4B68t",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8aIX1NP4B68t",
    "outputId": "3ad1dc69-e950-47aa-df8e-1f8ab854bd89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.7063317  -1.73159338 -2.4009437  ...  0.66122914  0.50700683\n",
      "   0.48114565]\n",
      " [-1.7063317  -1.7306784  -2.4009437  ...  0.66122914  0.50700683\n",
      "   0.48114565]\n",
      " [-1.7063317  -1.72976343 -2.4009437  ...  0.66122914  0.50700683\n",
      "   0.48114565]\n",
      " ...\n",
      " [ 1.57530322  1.72976343  1.60100689 ...  0.45524262  0.18837923\n",
      "   0.19455174]\n",
      " [ 1.57530322  1.7306784   1.66661264 ...  0.45524262  0.18837923\n",
      "   0.19455174]\n",
      " [ 1.57530322  1.73159338  1.73221839 ...  0.45524262  0.18837923\n",
      "   0.19455174]]\n",
      "-----------------------------------------------------------------\n",
      "[[ 6.75 86.  ]\n",
      " [ 6.75 86.  ]\n",
      " [ 6.75 86.  ]\n",
      " ...\n",
      " [23.25 88.5 ]\n",
      " [23.25 88.5 ]\n",
      " [23.5  88.5 ]]\n"
     ]
    }
   ],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "print(X)\n",
    "print(\"-----------------------------------------------------------------\")\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "qmvbMLaoI7kF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qmvbMLaoI7kF",
    "outputId": "add69084-59dd-495f-cc5e-051b2bd74bf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last index number of Cyclone :45 is 3457 and k = 3458\n"
     ]
    }
   ],
   "source": [
    "cyclone_number = 45\n",
    "\n",
    "# Get the index of the specific cyclone in New_df\n",
    "index_number =df2.index[df2['Number'] == cyclone_number].tolist()\n",
    "\n",
    "k=index_number[-1]+1\n",
    "# Print the index number\n",
    "print(\"Last index number of Cyclone :\"+str(cyclone_number) +' is',index_number[-1],'and k =',k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd08e728",
   "metadata": {
    "id": "cd08e728"
   },
   "outputs": [],
   "source": [
    "# Splitting without randomize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# k = 2050 #index for 55'th cyclone\n",
    "\n",
    "X_train = X[:k,:]\n",
    "X_test = X[k:,:]\n",
    "\n",
    "Y_train = Y[:k]\n",
    "Y_test= Y[k:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f0fd5bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3458, 2734), (328, 2734), (3458, 2), (328, 2))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape,Y_train.shape,Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b2d6929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.7063317 , -1.73159338, -2.4009437 , ...,  0.66122914,\n",
       "         0.50700683,  0.48114565],\n",
       "       [-1.7063317 , -1.7306784 , -2.4009437 , ...,  0.66122914,\n",
       "         0.50700683,  0.48114565],\n",
       "       [-1.7063317 , -1.72976343, -2.4009437 , ...,  0.66122914,\n",
       "         0.50700683,  0.48114565],\n",
       "       ...,\n",
       "       [ 1.30183364,  1.42965107, -0.69519427, ..., -1.49132173,\n",
       "        -1.51466171, -1.40813222],\n",
       "       [ 1.30183364,  1.43056605, -0.69519427, ..., -1.49132173,\n",
       "        -1.51466171, -1.40813222],\n",
       "       [ 1.30183364,  1.43148103, -0.69519427, ..., -1.49132173,\n",
       "        -1.51466171, -1.40813222]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc404089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3458, 2734)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39aa28f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "# X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "# # X_train.shape\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1],1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "44daa292",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sanjid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sanjid\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sanjid' is not defined"
     ]
    }
   ],
   "source": [
    "sanjid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a9b14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# arr = np.array([1, 2, 3, 4, 5, 6])\n",
    "# reshaped_arr = arr.reshape(2, 3,1)\n",
    "# reshaped_arr = arr.reshape(3, -1)\n",
    "\n",
    "# reshaped_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb53581",
   "metadata": {},
   "source": [
    "# Lstm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1d9b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import tensorflow as tf\n",
    "\n",
    "# # Define the LSTM-based RNN model\n",
    "# def build_lstm_rnn(input_shape, num_classes):\n",
    "#     model = tf.keras.Sequential([\n",
    "#         tf.keras.layers.LSTM(64, return_sequences=True, input_shape=input_shape),\n",
    "#         tf.keras.layers.Dropout(0.2),\n",
    "#         tf.keras.layers.LSTM(64),\n",
    "#         tf.keras.layers.Dropout(0.2),\n",
    "#         tf.keras.layers.Dense(num_classes)\n",
    "#     ])\n",
    "#     return model\n",
    "\n",
    "# # Define input shape and number of classes (output categories)\n",
    "# input_shape = (2734,1)  # Since you have 2734 features\n",
    "# num_classes = 2  # Since you have 2 classes\n",
    "\n",
    "# # # Reshape the data for LSTM\n",
    "# # X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "# # X_test=X_test.reshape(X_train.shape[0],X_train.shape[1],1)\n",
    "\n",
    "# # Create the LSTM RNN model\n",
    "# model = build_lstm_rnn(input_shape, num_classes)\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss='mean_squared_error',  # Adjust loss based on your problem\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(X_train, Y_train,validation_split=0.2 ,epochs=50, batch_size=50, verbose=1)\n",
    "\n",
    "# model.save('/home/sanjid/Projects/ML_TCBOB/LSTM/Lstm -1/lstm-1.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe51e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "# print('Loss: {}'.format(loss))\n",
    "# print('Accuracy: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0cf353",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5772eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f65755",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395a5106",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_test = Y_test[:,0]\n",
    "lat_test = Y_test[:,1]\n",
    "\n",
    "lon_pred = Y_pred[:,0]\n",
    "lat_pred = Y_pred[:,1]\n",
    "\n",
    "random_dataset = pd.DataFrame()\n",
    "random_dataset['lon_test'] = lon_test\n",
    "random_dataset['lat_test'] = lat_test\n",
    "\n",
    "random_dataset['lon_pred'] = lon_pred\n",
    "random_dataset['lat_pred'] = lat_pred\n",
    "random_dataset['deviation'] = np.sqrt(((lon_test-lon_pred)**2)+ ((lat_test-lat_pred)**2))\n",
    "\n",
    "print(\"  \")\n",
    "print(\"The average error for the deviation is \"+ str(random_dataset['deviation'].mean()))\n",
    "print(\"  \")\n",
    "\n",
    "random_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e349ff02",
   "metadata": {},
   "source": [
    "#  Lstm-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67a68b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# Define the LSTM-based RNN model\n",
    "def build_lstm_rnn(input_shape, num_classes):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(64, return_sequences=True, input_shape=input_shape),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.LSTM(64),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(num_classes)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Define input shape and number of classes (output categories)\n",
    "input_shape = (2734, 1)  # Since you have 2734 features\n",
    "num_classes = 2  # Since you have 2 classes\n",
    "\n",
    "\n",
    "# Create the LSTM RNN model\n",
    "model = build_lstm_rnn(input_shape, num_classes)\n",
    "\n",
    "# Compile the model with Huber loss and Adam optimizer\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.Huber(),  # Huber loss function\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),  # Adam optimizer with learning rate of 0.001\n",
    "    metrics=['mean_absolute_error']  # Monitor mean absolute error\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, Y_train, validation_split=0.2, epochs=50, batch_size=50, verbose=1)\n",
    "\n",
    "# Save the model\n",
    "model.save('/home/sanjid/Projects/ML_TCBOB/LSTM/lstm-2/lstm-2.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217c21f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94a49e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a8f257",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_test = Y_test[:,0]\n",
    "lat_test = Y_test[:,1]\n",
    "\n",
    "lon_pred = Y_pred[:,0]\n",
    "lat_pred = Y_pred[:,1]\n",
    "\n",
    "random_dataset = pd.DataFrame()\n",
    "random_dataset['lon_test'] = lon_test\n",
    "random_dataset['lat_test'] = lat_test\n",
    "\n",
    "random_dataset['lon_pred'] = lon_pred\n",
    "random_dataset['lat_pred'] = lat_pred\n",
    "random_dataset['deviation'] = np.sqrt(((lon_test-lon_pred)**2)+ ((lat_test-lat_pred)**2))\n",
    "\n",
    "print(\"  \")\n",
    "print(\"The average error for the deviation is \"+ str(random_dataset['deviation'].mean()))\n",
    "print(\"  \")\n",
    "\n",
    "random_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eefb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_dataset.head(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457c1426",
   "metadata": {},
   "source": [
    "# Lstm - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e770cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the LSTM-based RNN model with Bidirectional layer\n",
    "def build_bidirectional_lstm_rnn(input_shape, num_classes):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True), input_shape=input_shape),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(num_classes)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Define input shape and number of classes (output categories)\n",
    "input_shape = (2734, 1)  # Since you have 2734 features\n",
    "num_classes = 2  # Since you have 2 classes\n",
    "\n",
    "# Create the LSTM RNN model with Bidirectional layer\n",
    "model = build_bidirectional_lstm_rnn(input_shape, num_classes)\n",
    "\n",
    "# Compile the model with Huber loss and Adam optimizer\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.Huber(),  # Huber loss function\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),  # Adam optimizer with learning rate of 0.001\n",
    "    metrics=['mean_absolute_error']  # Monitor mean absolute error\n",
    ")\n",
    "model.summary()\n",
    "# Train the model\n",
    "model.fit(X_train, Y_train, validation_split=0.2, epochs=50, batch_size=50, verbose=1)\n",
    "\n",
    "# Save the model\n",
    "model.save('/home/sanjid/Projects/ML_TCBOB/LSTM/lstm-3/lstm-3-bidirectional.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b504975",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466e5083",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_test = Y_test[:,0]\n",
    "lat_test = Y_test[:,1]\n",
    "\n",
    "lon_pred = Y_pred[:,0]\n",
    "lat_pred = Y_pred[:,1]\n",
    "\n",
    "random_dataset = pd.DataFrame()\n",
    "random_dataset['lon_test'] = lon_test\n",
    "random_dataset['lat_test'] = lat_test\n",
    "\n",
    "random_dataset['lon_pred'] = lon_pred\n",
    "random_dataset['lat_pred'] = lat_pred\n",
    "random_dataset['deviation'] = np.sqrt(((lon_test-lon_pred)**2)+ ((lat_test-lat_pred)**2))\n",
    "\n",
    "print(\"  \")\n",
    "print(\"The average error for the deviation is \"+ str(random_dataset['deviation'].mean()))\n",
    "print(\"  \")\n",
    "\n",
    "random_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2143a95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_dataset.head(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49550671",
   "metadata": {},
   "source": [
    "# Lstm-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43abc71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-02 22:35:44.098790: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-10-02 22:35:44.316902: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-02 22:35:44.317851: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-02 22:35:44.318564: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-10-02 22:35:44.439639: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-02 22:35:44.440394: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-02 22:35:44.441064: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-02 22:35:44.569682: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-02 22:35:44.570658: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-02 22:35:44.571363: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-10-02 22:35:44.856025: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-02 22:35:44.857208: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-02 22:35:44.858062: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-10-02 22:35:44.992756: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-02 22:35:44.993720: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-02 22:35:44.994587: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-10-02 22:35:45.152077: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-02 22:35:45.158334: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-02 22:35:45.159704: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-10-02 22:35:46.087629: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-02 22:35:46.088792: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-02 22:35:46.089690: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-10-02 22:35:46.230108: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-02 22:35:46.231048: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-02 22:35:46.231874: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-10-02 22:35:46.377984: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-02 22:35:46.379120: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-02 22:35:46.379999: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - ETA: 0s - loss: 45.9788 - mean_absolute_error: 46.4781"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-02 22:44:55.981990: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-02 22:44:55.983123: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-02 22:44:55.983958: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-10-02 22:44:56.132264: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-02 22:44:56.133292: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-02 22:44:56.134247: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-10-02 22:44:56.285378: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-02 22:44:56.286430: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-02 22:44:56.287248: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 590s 10s/step - loss: 45.9788 - mean_absolute_error: 46.4781 - val_loss: 41.5447 - val_mean_absolute_error: 42.0447\n",
      "Epoch 2/35\n",
      "56/56 [==============================] - 577s 10s/step - loss: 39.7062 - mean_absolute_error: 40.1998 - val_loss: 37.5890 - val_mean_absolute_error: 38.0707\n",
      "Epoch 3/35\n",
      "56/56 [==============================] - 548s 10s/step - loss: 36.6079 - mean_absolute_error: 37.0946 - val_loss: 35.1707 - val_mean_absolute_error: 35.6502\n",
      "Epoch 4/35\n",
      "56/56 [==============================] - 551s 10s/step - loss: 34.3386 - mean_absolute_error: 34.8260 - val_loss: 33.1920 - val_mean_absolute_error: 33.6800\n",
      "Epoch 5/35\n",
      "56/56 [==============================] - 557s 10s/step - loss: 32.3814 - mean_absolute_error: 32.8677 - val_loss: 31.3154 - val_mean_absolute_error: 31.8064\n",
      "Epoch 6/35\n",
      "56/56 [==============================] - 611s 11s/step - loss: 30.5020 - mean_absolute_error: 30.9894 - val_loss: 29.4549 - val_mean_absolute_error: 29.9470\n",
      "Epoch 7/35\n",
      "56/56 [==============================] - 586s 10s/step - loss: 28.6374 - mean_absolute_error: 29.1261 - val_loss: 27.5985 - val_mean_absolute_error: 28.0906\n",
      "Epoch 8/35\n",
      "56/56 [==============================] - 536s 10s/step - loss: 26.7720 - mean_absolute_error: 27.2602 - val_loss: 25.7553 - val_mean_absolute_error: 26.2474\n",
      "Epoch 9/35\n",
      "56/56 [==============================] - 545s 10s/step - loss: 24.9454 - mean_absolute_error: 25.4334 - val_loss: 23.9226 - val_mean_absolute_error: 24.4147\n",
      "Epoch 10/35\n",
      "56/56 [==============================] - 573s 10s/step - loss: 23.1109 - mean_absolute_error: 23.5978 - val_loss: 22.0933 - val_mean_absolute_error: 22.5854\n",
      "Epoch 11/35\n",
      "56/56 [==============================] - 562s 10s/step - loss: 21.3016 - mean_absolute_error: 21.7890 - val_loss: 20.2738 - val_mean_absolute_error: 20.7659\n",
      "Epoch 12/35\n",
      "56/56 [==============================] - 564s 10s/step - loss: 19.4694 - mean_absolute_error: 19.9570 - val_loss: 18.4506 - val_mean_absolute_error: 18.9427\n",
      "Epoch 13/35\n",
      "56/56 [==============================] - 560s 10s/step - loss: 17.7085 - mean_absolute_error: 18.1962 - val_loss: 16.6392 - val_mean_absolute_error: 17.1313\n",
      "Epoch 14/35\n",
      "56/56 [==============================] - 530s 9s/step - loss: 15.9077 - mean_absolute_error: 16.3952 - val_loss: 14.8325 - val_mean_absolute_error: 15.3250\n",
      "Epoch 15/35\n",
      "56/56 [==============================] - 532s 10s/step - loss: 14.0409 - mean_absolute_error: 14.5287 - val_loss: 13.0208 - val_mean_absolute_error: 13.5129\n",
      "Epoch 16/35\n",
      "56/56 [==============================] - 544s 10s/step - loss: 12.2614 - mean_absolute_error: 12.7492 - val_loss: 11.2106 - val_mean_absolute_error: 11.7026\n",
      "Epoch 17/35\n",
      "56/56 [==============================] - 552s 10s/step - loss: 10.4277 - mean_absolute_error: 10.9149 - val_loss: 9.4060 - val_mean_absolute_error: 9.8980\n",
      "Epoch 18/35\n",
      "56/56 [==============================] - 560s 10s/step - loss: 8.6630 - mean_absolute_error: 9.1513 - val_loss: 7.6208 - val_mean_absolute_error: 8.1135\n",
      "Epoch 19/35\n",
      "56/56 [==============================] - 548s 10s/step - loss: 6.8918 - mean_absolute_error: 7.3784 - val_loss: 5.8861 - val_mean_absolute_error: 6.3782\n",
      "Epoch 20/35\n",
      "27/56 [=============>................] - ETA: 4:36 - loss: 5.7825 - mean_absolute_error: 6.2678"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the LSTM and GRU-based RNN model\n",
    "def build_lstm_gru_rnn(input_shape, num_classes):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(64, return_sequences=True, input_shape=input_shape),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.GRU(64, return_sequences=True),  # Added GRU layer\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.LSTM(64),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(num_classes)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Define input shape and number of classes (output categories)\n",
    "input_shape = (2734, 1)  # Since you have 2734 features\n",
    "num_classes = 2  # Since you have 2 classes\n",
    "\n",
    "# Create the LSTM and GRU RNN model\n",
    "model = build_lstm_gru_rnn(input_shape, num_classes)\n",
    "\n",
    "# Compile the model with Huber loss and Adam optimizer\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.Huber(),  # Huber loss function\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),  # Adam optimizer with learning rate of 0.001\n",
    "    metrics=['mean_absolute_error']  # Monitor mean absolute error\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, Y_train, validation_split=0.2, epochs=35, batch_size=50, verbose=1)\n",
    "\n",
    "# Save the model\n",
    "model.save('/home/sanjid/Projects/ML_TCBOB/LSTM/lstm-4/lstm_gru.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6267df67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# # Define the LSTM and GRU-based RNN model\n",
    "# def build_lstm_gru_rnn(input_shape, num_classes):\n",
    "#     model = tf.keras.Sequential([\n",
    "#         tf.keras.layers.LSTM(64, return_sequences=True, input_shape=input_shape),\n",
    "#         tf.keras.layers.Dropout(0.2),\n",
    "#         tf.keras.layers.GRU(64, return_sequences=True),  # Added GRU layer\n",
    "#         tf.keras.layers.Dropout(0.2),\n",
    "#         tf.keras.layers.LSTM(64),\n",
    "#         tf.keras.layers.Dropout(0.2),\n",
    "#         tf.keras.layers.Dense(num_classes)\n",
    "#     ])\n",
    "#     return model\n",
    "\n",
    "# # Define input shape and number of classes (output categories)\n",
    "# input_shape = (2734, 1)  # Since you have 2734 features\n",
    "# num_classes = 2  # Since you have 2 classes\n",
    "\n",
    "# # Create a MirroredStrategy.\n",
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# with strategy.scope():\n",
    "#     # Everything that creates variables should be under the strategy scope.\n",
    "#     # In general, this is only model construction & `compile`.\n",
    "#     model = build_lstm_gru_rnn(input_shape, num_classes)\n",
    "\n",
    "#     # Compile the model with Huber loss and Adam optimizer\n",
    "#     model.compile(\n",
    "#         loss=tf.keras.losses.Huber(),  # Huber loss function\n",
    "#         optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),  # Adam optimizer with learning rate of 0.001\n",
    "#         metrics=['mean_absolute_error']  # Monitor mean absolute error\n",
    "#     )\n",
    "\n",
    "#     # Train the model\n",
    "#     model.fit(X_train, Y_train, validation_split=0.2, epochs=50, batch_size=50, verbose=1)\n",
    "\n",
    "#     # Save the model\n",
    "#     model.save('/home/sanjid/Projects/ML_TCBOB/LSTM/lstm_gru/lstm_gru.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084469b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14f20cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753c7f03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179a8897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a98b96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecbdc81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd31bfe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeffe89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42193d82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c28cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0d3d91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4938e21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c375f314",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627e06de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bed1e42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531f8180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04cb112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56cd9e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b990da4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127c2873",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b590f719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0d6d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f92dc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dd6295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405b8abc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4f97ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffa8bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sanjid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258e5b8a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the LSTM-based RNN model\n",
    "def build_lstm_rnn(input_shape, num_classes):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(64, return_sequences=True, input_shape=input_shape),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.LSTM(64),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Define input shape and number of classes (output categories)\n",
    "input_shape = (X_train.shape[1], 2)  # Assuming each feature is a time step\n",
    "num_classes = Y_train.shape[1]  # Assuming you have 2 classes\n",
    "\n",
    "# Create the LSTM RNN model\n",
    "model = build_lstm_rnn(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define a model checkpoint to save the best model\n",
    "checkpoint_filepath = 'best_model.h5'\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_accuracy',  # You can also use 'val_loss'\n",
    "    mode='max',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, Y_train, epochs=10, batch_size=32, verbose=1, validation_data=(X_test, Y_test), callbacks=[model_checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7e840c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d223f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dcafdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaa2d70",
   "metadata": {
    "id": "aaaa2d70"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34df8ecd",
   "metadata": {
    "id": "34df8ecd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7a4f76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f7d22d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "R-tmziQDBu2V",
   "metadata": {
    "id": "R-tmziQDBu2V"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Dvi8Bds_wBox",
   "metadata": {
    "id": "Dvi8Bds_wBox"
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "# model_conv1D.save('/content/drive/MyDrive/Colab Notebooks/ML_TCBOB/Scripts/Models/conv1d with callbacks')\n",
    "\n",
    "# # To load the model later:\n",
    "# # loaded_model = tf.keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/ML_TCBOB/Scripts/Models/conv1d with callbacks')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NXTKixyoIG3X",
   "metadata": {
    "id": "NXTKixyoIG3X"
   },
   "source": [
    "# Model with MirroredStratagey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9GoYU52fGVYx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9GoYU52fGVYx",
    "outputId": "6acbb7a9-6db7-4b94-df14-ac5a0c826482"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "# Define the MirroredStrategy\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "def build_conv1D_model():\n",
    "    n_timesteps = X_train1.shape[1]\n",
    "    n_features  = X_train1.shape[2]\n",
    "\n",
    "    with strategy.scope():  # Wrap the model creation in the strategy.scope()\n",
    "        model = keras.Sequential(name=\"model_conv1D\")\n",
    "        model.add(keras.layers.Input(shape=(n_timesteps, n_features)))\n",
    "        model.add(keras.layers.Conv1D(filters=64, kernel_size=24, activation='relu', name=\"Conv1D_3\"))\n",
    "        model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)))\n",
    "        model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=False)))\n",
    "        model.add(keras.layers.Flatten())\n",
    "        model.add(keras.layers.Dense(32, activation='linear', name=\"Dense_1\"))\n",
    "        model.add(keras.layers.Dense(2, name=\"Dense_2\"))\n",
    "\n",
    "        optimizer = tf.keras.optimizers.RMSprop(lr=1e-5, momentum=0.9)\n",
    "\n",
    "        model.compile(loss=\"mse\", optimizer=optimizer, metrics=['mae'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model_conv1D = build_conv1D_model()\n",
    "model_conv1D.summary()\n",
    "\n",
    "# Now, train the model without the callbacks\n",
    "with strategy.scope():\n",
    "    history = model_conv1D.fit(X_train1, Y_train, epochs=100, batch_size=24, verbose=1, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NznVjEAOIhM_",
   "metadata": {
    "id": "NznVjEAOIhM_"
   },
   "source": [
    "# Saving and loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gB5hEo6kQkPL",
   "metadata": {
    "id": "gB5hEo6kQkPL"
   },
   "outputs": [],
   "source": [
    "# # # Save the model\n",
    "# # model_conv1D.save('/content/drive/MyDrive/Colab Notebooks/ML_TCBOB/Scripts/Models/conv1d with mirror')\n",
    "\n",
    "# # # To load the model later:\n",
    "# loaded_model = tf.keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/ML_TCBOB/Scripts/Models/conv1d with mirror')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3c7e51",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "5b3c7e51",
    "outputId": "ce00d62a-70dc-4d7a-85bc-38200196e628"
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# # print(history.history.keys())\n",
    "\n",
    "# # summarize history for accuracy\n",
    "# #with plt.style.context('ggplot'):\n",
    "# plt.figure(dpi=110)\n",
    "# plt.plot(history.history['mae'])\n",
    "# plt.plot(history.history['val_mae'])\n",
    "# plt.title('Mean Absolute error')\n",
    "# plt.ylabel('Error')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# # summarize history for loss\n",
    "# #with plt.style.context('ggplot'):\n",
    "# plt.figure(dpi=110)\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('Loss')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SGyNUiJiHqPW",
   "metadata": {
    "id": "SGyNUiJiHqPW"
   },
   "source": [
    "# Using the loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a61db1c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8a61db1c",
    "outputId": "dbf0583b-41e0-4624-d8ca-cf8f47a4e32a"
   },
   "outputs": [],
   "source": [
    "# Y_pred = model_conv1D.predict(X_test1)\n",
    "Y_pred = loaded_model.predict(X_test1)\n",
    "\n",
    "Y_pred = Y_pred\n",
    "print(Y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380663e1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "id": "380663e1",
    "outputId": "b1b7813e-4b90-4a87-bb1b-e41215c85941"
   },
   "outputs": [],
   "source": [
    "lon_test = Y_test[:,0]\n",
    "lat_test = Y_test[:,1]\n",
    "\n",
    "lon_pred = Y_pred[:,0]\n",
    "lat_pred = Y_pred[:,1]\n",
    "\n",
    "random_dataset = pd.DataFrame()\n",
    "random_dataset['lon_test'] = lon_test\n",
    "random_dataset['lat_test'] = lat_test\n",
    "\n",
    "random_dataset['lon_pred'] = lon_pred\n",
    "random_dataset['lat_pred'] = lat_pred\n",
    "random_dataset['deviation'] = np.sqrt(((lon_test-lon_pred)**2)+ ((lat_test-lat_pred)**2))\n",
    "\n",
    "print(\"  \")\n",
    "print(\"The average error for the deviation is \"+ str(random_dataset['deviation'].mean()))\n",
    "print(\"  \")\n",
    "\n",
    "random_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af33322",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 820
    },
    "id": "1af33322",
    "outputId": "f10fb039-ddc9-4b85-b487-850ae497f5f6"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,4))\n",
    "plt.plot(lon_test, label='Lon Test')\n",
    "plt.plot(lon_pred, label='Lon Predition')\n",
    "plt.xlabel('Value index')\n",
    "plt.ylabel('Longitude Value')\n",
    "plt.ylim(80,100)\n",
    "plt.title(\"Longitude prediction with ANN\")\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(figsize=(14,4))\n",
    "plt.plot(lat_test, label='Lat Test')\n",
    "plt.plot(lat_pred, label='Lat Predition')\n",
    "plt.xlabel('Value index')\n",
    "plt.ylabel('Latitude Value')\n",
    "plt.ylim(5, 25)\n",
    "plt.title(\"Latitude prediction with ANN\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909e68e9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "id": "909e68e9",
    "outputId": "de6002bc-aaf1-455d-8f29-c700b4aefa9c"
   },
   "outputs": [],
   "source": [
    "X_original_scale = sc.inverse_transform(X_test)\n",
    "cyclone_number=X_original_scale[:,1]\n",
    "\n",
    "lon_test = Y_test[:,0]\n",
    "lat_test = Y_test[:,1]\n",
    "\n",
    "lon_pred = Y_pred[:,0]\n",
    "lat_pred = Y_pred[:,1]\n",
    "\n",
    "random_dataset = pd.DataFrame()\n",
    "random_dataset['cyclone_number'] = cyclone_number\n",
    "random_dataset['lon_test'] = lon_test\n",
    "random_dataset['lat_test'] = lat_test\n",
    "\n",
    "random_dataset['lon_pred'] = lon_pred\n",
    "random_dataset['lat_pred'] = lat_pred\n",
    "random_dataset['deviation'] = np.sqrt(((lon_test-lon_pred)**2)+ ((lat_test-lat_pred)**2))\n",
    "\n",
    "print(\"  \")\n",
    "print(\"The average error for the deviation is \"+ str(random_dataset['deviation'].mean()))\n",
    "print(\"  \")\n",
    "\n",
    "random_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HX7oUg7w0_zt",
   "metadata": {
    "id": "HX7oUg7w0_zt"
   },
   "outputs": [],
   "source": [
    "# !apt-get install -qq libgdal-dev libproj-dev\n",
    "# #!pip install --no-binary shapely shapely\n",
    "# !pip install --no-binary shapely shapely --force\n",
    "# !pip install cartopy\n",
    "# import cartopy.crs as ccrs\n",
    "# import cartopy.feature as cfeature\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701699cc",
   "metadata": {
    "id": "701699cc"
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import cartopy.crs as ccrs\n",
    "\n",
    "# fig, axs = plt.subplots(3, 4, figsize=(16, 18), dpi=100, subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "# for i in range(3):\n",
    "#     for j in range(4):\n",
    "#         # Taking the cyclone number from input\n",
    "#         cyclone_number = i * 4 + j + 45\n",
    "\n",
    "#         # Separating the data for the desired cyclone\n",
    "#         cyclone_data = random_dataset[random_dataset['cyclone_number'] == float(cyclone_number)]\n",
    "#         # cyclone_data = cyclone_data.drop(cyclone_data.index[0]) #removing the last row as it creates problem\n",
    "\n",
    "#         # Plotting the cyclone data\n",
    "#         axs[i, j].plot(cyclone_data['lon_test'], cyclone_data['lat_test'], '-o', markersize=2.5, transform=ccrs.PlateCarree())\n",
    "#         axs[i, j].plot(cyclone_data['lon_pred'], cyclone_data['lat_pred'], '-o', markersize=2.5, transform=ccrs.PlateCarree())\n",
    "#         axs[i, j].set_extent([70, 100, 5, 30], crs=ccrs.PlateCarree())\n",
    "#         axs[i, j].coastlines(linewidth=1.4)\n",
    "#         axs[i, j].gridlines(draw_labels=True)\n",
    "#         axs[i, j].set_title(f\"Cyclone {cyclone_number}\")\n",
    "#         # axs[i,j].legend(['Test', 'Prediction'], loc='upper left')\n",
    "\n",
    "# # Set the overall title for the subplot\n",
    "# fig.suptitle(\"6h Prediction no prev feature\", fontsize=20, y=1)\n",
    "# fig.legend(['Test', 'Prediction'], loc='upper left')\n",
    "\n",
    "# # Adjust spacing between subplots\n",
    "# fig.tight_layout()\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oDpkx618k3Gf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "oDpkx618k3Gf",
    "outputId": "d6d3d8fb-07f7-47d3-d594-6f908c27973a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "def plot_cyclone_data(cyclone_data_list):\n",
    "    num_cyclones = len(cyclone_data_list)\n",
    "    num_rows = (num_cyclones + 3) // 4  # Round up to the nearest multiple of 4\n",
    "    fig, axs = plt.subplots(num_rows, 4, figsize=(24, 18), dpi=150, subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    axs = axs.ravel()\n",
    "\n",
    "    for i, cyclone_data in enumerate(cyclone_data_list):\n",
    "        ax = axs[i]\n",
    "        ax.plot(cyclone_data['lon_test'], cyclone_data['lat_test'], '-o', markersize=2.5, transform=ccrs.PlateCarree())\n",
    "        ax.plot(cyclone_data['lon_pred'], cyclone_data['lat_pred'], '-o', markersize=2.5, transform=ccrs.PlateCarree())\n",
    "        ax.set_extent([78, 100, 0, 30], crs=ccrs.PlateCarree())\n",
    "        ax.coastlines(linewidth=1.4)\n",
    "        ax.gridlines(draw_labels=True)\n",
    "        ax.set_title(f\"Cyclone {cyclone_data['cyclone_number'].iloc[0]}\")\n",
    "        ax.legend(['Test', 'Prediction'], loc='upper left')\n",
    "\n",
    "    # Adjust spacing between subplots\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Taking the cyclone numbers from 46 to 58\n",
    "cyclone_numbers = list(range(46, 58))\n",
    "\n",
    "# Separating the data for the desired cyclones\n",
    "cyclone_data_list = [random_dataset[random_dataset['cyclone_number'] == float(cyclone_number)] for cyclone_number in cyclone_numbers]\n",
    "\n",
    "# Plotting the cyclone data\n",
    "plot_cyclone_data(cyclone_data_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MaztTUGXAexI",
   "metadata": {
    "id": "MaztTUGXAexI"
   },
   "outputs": [],
   "source": [
    "## take from lat from 78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xK1KXuXyj9iz",
   "metadata": {
    "id": "xK1KXuXyj9iz"
   },
   "outputs": [],
   "source": [
    "def plot_cyclone_data(cyclone_data):\n",
    "    fig = plt.figure(figsize=(20, 12))\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "    ax.plot(cyclone_data['lon_test'], cyclone_data['lat_test'], '-o', markersize=5, transform=ccrs.PlateCarree())\n",
    "    ax.plot(cyclone_data['lon_pred'], cyclone_data['lat_pred'], '-o', markersize=5, transform=ccrs.PlateCarree())\n",
    "    ax.set_extent([80, 100, 0, 30], crs=ccrs.PlateCarree())\n",
    "    ax.coastlines(linewidth=1.4)\n",
    "    ax.gridlines(draw_labels=True)\n",
    "    plt.legend(['Test', 'Prediction'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Taking the cyclone number from input\n",
    "cyclone_number = input(\"Enter cyclone number: \")\n",
    "\n",
    "# Separating the data for the desired cyclone\n",
    "cyclone_data = random_dataset[random_dataset['cyclone_number'] == float(cyclone_number)]\n",
    "\n",
    "# Plotting the cyclone data\n",
    "\n",
    "plot_cyclone_data(cyclone_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbhdBO-VVVhQ",
   "metadata": {
    "id": "bbhdBO-VVVhQ"
   },
   "source": [
    "# Run this cell for same initial point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3RSru-cvSFIc",
   "metadata": {
    "id": "3RSru-cvSFIc"
   },
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(4, 4, figsize=(16, 18), dpi=100, subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "# for i in range(4):\n",
    "#     for j in range(4):\n",
    "#         # Taking the cyclone number from input\n",
    "#         cyclone_number = i*4 + j + 53\n",
    "\n",
    "#         # Separating the data for the desired cyclone\n",
    "#         cyclone_data = random_dataset[random_dataset['cyclone_number'] == float(cyclone_number)]\n",
    "\n",
    "#         # Get the first point of lat_test and lon_test\n",
    "#         first_lat_test = cyclone_data['lat_test'].iloc[0]\n",
    "#         first_lon_test = cyclone_data['lon_test'].iloc[0]\n",
    "#         # Create a new DataFrame with the newly added columns\n",
    "#         plot_df=pd.DataFrame({\n",
    "#             'lat_pred':[first_lat_test]+cyclone_data['lat_pred'].tolist(),\n",
    "#             'lon_pred':[first_lon_test]+cyclone_data['lon_pred'].tolist(),\n",
    "#         })\n",
    "\n",
    "#         # Plotting the cyclone data\n",
    "#         axs[i,j].plot(cyclone_data['lon_test'], cyclone_data['lat_test'], '-o', markersize=2.5, transform=ccrs.PlateCarree())\n",
    "#         axs[i,j].plot(plot_df['lon_pred'], plot_df['lat_pred'], '-o', markersize=2.5, transform=ccrs.PlateCarree())\n",
    "#         axs[i,j].set_extent([80, 100, 5, 30], crs=ccrs.PlateCarree())\n",
    "#         axs[i,j].coastlines(linewidth=1.4)\n",
    "#         axs[i,j].gridlines(draw_labels=True)\n",
    "#         axs[i,j].set_title(f\"Cyclone {cyclone_number}\")\n",
    "# # Set the overall title for the subplot\n",
    "# fig.suptitle(\"6h Prediction no prev feature\", fontsize=20, y=1)\n",
    "# fig.legend(['Test', 'Prediction'], loc='upper left')\n",
    "\n",
    "# # Adjust spacing between subplots\n",
    "# fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TVHdl0_-VcK4",
   "metadata": {
    "id": "TVHdl0_-VcK4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
